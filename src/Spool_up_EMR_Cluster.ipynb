{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "productive-circulation",
   "metadata": {},
   "source": [
    "# Spool up EMR Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prerequisite-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "import sys\n",
    "import botocore\n",
    "import paramiko\n",
    "import re\n",
    "import os\n",
    "import yaml, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "charitable-karma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/hail-on-AWS-spot-instances/src'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = os.path.abspath(os.getcwd())\n",
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "considerable-holiday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021021016\n"
     ]
    }
   ],
   "source": [
    "#Setup logging\n",
    "import logging, bluebee\n",
    "from bluebee import bgp\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# create file handler which logs even debug messages\n",
    "logFile = f'{PATH}/spoolup_EMR_cluster.log'\n",
    "fh = logging.FileHandler(logFile)\n",
    "fh.setLevel(logging.INFO)\n",
    "# create console handler with a higher log level\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)-18s-%(levelname)-8s %(message)s', datefmt='%d%b%Y %H:%M:%S')\n",
    "ch.setFormatter(formatter)\n",
    "fh.setFormatter(formatter)\n",
    "# add the handlers to logger\n",
    "logger.addHandler(ch)\n",
    "logger.addHandler(fh)\n",
    "# bgp.api.dump_curl = True\n",
    "# bluebee.logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "italian-share",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 00:39:25-INFO     Configuration settings: {'config': {'EMR_CLUSTER_NAME': 'tdeboer-hail', 'EC2_NAME_TAG': 'tdeboer-hail-EMR', 'OWNER_TAG': 'tdeboer-ilmn', 'PROJECT_TAG': 'GRE_on_ICA', 'REGION': 'us-east-1', 'MASTER_INSTANCE_TYPE': 'm4.large', 'WORKER_INSTANCE_TYPE': 'r4.4xlarge', 'WORKER_COUNT': '4', 'WORKER_BID_PRICE': '0.50', 'MASTER_HD_SIZE': '250', 'WORKER_HD_SIZE': '500', 'SUBNET_ID': '', 'S3_BUCKET': 's3n://ilmn-hail/', 'KEY_NAME': 'hail-ES-GRE', 'PATH_TO_KEY': '/data/', 'WORKER_SECURITY_GROUP': 'sg-0df1e5704ca2a8196', 'MASTER_SECURITY_GROUP': 'sg-0bab1202c0aa453b3', 'HAIL_VERSION': 'current'}}\n"
     ]
    }
   ],
   "source": [
    "#Get the configuration as a yaml object\n",
    "c=yaml.load(open(PATH+\"/config_EMR_spot.yaml\"),Loader=yaml.SafeLoader)\n",
    "logger.info(f'Configuration settings: {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "likely-palestine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 00:39:25-INFO     Executing following command: \n",
      "aws emr create-cluster --applications Name=Hadoop Name=Spark --tags 'project=GRE_on_ICA' 'Owner=tdeboer-ilmn' 'Name=tdeboer-hail-EMR' --ec2-attributes '{\"KeyName\":\"hail-ES-GRE\",\"InstanceProfile\":\"EMR_EC2_DefaultRole\",\"SubnetId\":\"\",\"EmrManagedSlaveSecurityGroup\":\"sg-0df1e5704ca2a8196\",\"EmrManagedMasterSecurityGroup\":\"sg-0bab1202c0aa453b3\"}' --service-role EMR_DefaultRole --release-label emr-5.23.0 --log-uri 's3n://ilmn-hail/' --name 'tdeboer-hail' --instance-groups '[{\"InstanceCount\":1,\"EbsConfiguration\":{\"EbsBlockDeviceConfigs\":[{\"VolumeSpecification\":{\"SizeInGB\":250,\"VolumeType\":\"gp2\"},\"VolumesPerInstance\":1}]},\"InstanceGroupType\":\"MASTER\",\"InstanceType\":\"m4.large\",\"Name\":\"Master-Instance\"},{\"InstanceCount\":4,\"BidPrice\":\"0.50\",\"EbsConfiguration\":{\"EbsBlockDeviceConfigs\":[{\"VolumeSpecification\":{\"SizeInGB\":500,\"VolumeType\":\"gp2\"},\"VolumesPerInstance\":1}]},\"InstanceGroupType\":\"CORE\",\"InstanceType\":\"r4.4xlarge\",\"Name\":\"Core-Group\"}]' --configurations '[{\"Classification\":\"spark\",\"Properties\":{\"maximizeResourceAllocation\":\"true\"}},{\"Classification\":\"yarn-site\",\"Properties\":{\"yarn.nodemanager.vmem-check-enabled\":\"false\"},\"Configurations\":[]}]' --auto-scaling-role EMR_AutoScaling_DefaultRole --ebs-root-volume-size 32 --scale-down-behavior TERMINATE_AT_TASK_COMPLETION --region us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Spot instances and different CORE/MASTER instances\n",
    "command='aws emr create-cluster --applications Name=Hadoop Name=Spark --tags \\'project='+\\\n",
    "c['config']['PROJECT_TAG']+'\\' \\'Owner='+c['config']['OWNER_TAG']+\\\n",
    "'\\' \\'Name='+c['config']['EC2_NAME_TAG']+'\\' --ec2-attributes \\'{\"KeyName\":\"'+\\\n",
    "c['config']['KEY_NAME']+'\",\"InstanceProfile\":\"EMR_EC2_DefaultRole\",\"SubnetId\":\"'+\\\n",
    "c['config']['SUBNET_ID']+'\",\"EmrManagedSlaveSecurityGroup\":\"'+c['config']['WORKER_SECURITY_GROUP']+\\\n",
    "'\",\"EmrManagedMasterSecurityGroup\":\"'+c['config']['MASTER_SECURITY_GROUP']+\\\n",
    "'\"}\\' --service-role EMR_DefaultRole --release-label emr-5.23.0 --log-uri \\''+\\\n",
    "c['config']['S3_BUCKET']+'\\' --name \\''+c['config']['EMR_CLUSTER_NAME']+\\\n",
    "'\\' --instance-groups \\'[{\"InstanceCount\":1,\"EbsConfiguration\":{\"EbsBlockDeviceConfigs\":[{\"VolumeSpecification\":{\"SizeInGB\":'+\\\n",
    "c['config']['MASTER_HD_SIZE']+',\"VolumeType\":\"gp2\"},\"VolumesPerInstance\":1}]},\"InstanceGroupType\":\"MASTER\",\"InstanceType\":\"'+\\\n",
    "c['config']['MASTER_INSTANCE_TYPE']+'\",\"Name\":\"Master-Instance\"},{\"InstanceCount\":'+\\\n",
    "c['config']['WORKER_COUNT']+',\"BidPrice\":\"'+c['config']['WORKER_BID_PRICE']+\\\n",
    "'\",\"EbsConfiguration\":{\"EbsBlockDeviceConfigs\":[{\"VolumeSpecification\":{\"SizeInGB\":'+\\\n",
    "c['config']['WORKER_HD_SIZE']+',\"VolumeType\":\"gp2\"},\"VolumesPerInstance\":1}]},\"InstanceGroupType\":\"CORE\",\"InstanceType\":\"'+\\\n",
    "c['config']['WORKER_INSTANCE_TYPE']+\\\n",
    "'\",\"Name\":\"Core-Group\"}]\\' --configurations \\'[{\"Classification\":\"spark\",\"Properties\":{\"maximizeResourceAllocation\":\"true\"}},{\"Classification\":\"yarn-site\",\"Properties\":{\"yarn.nodemanager.vmem-check-enabled\":\"false\"},\"Configurations\":[]}]\\' --auto-scaling-role EMR_AutoScaling_DefaultRole --ebs-root-volume-size 32 --scale-down-behavior TERMINATE_AT_TASK_COMPLETION --region '+\\\n",
    "c['config']['REGION']\n",
    "logger.info(f'Executing following command: \\n{command}')\n",
    "assert os.system(command) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "enormous-benchmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 00:39:30-INFO     Found credentials in shared credentials file: ~/.aws/credentials\n",
      "25Mar2021 00:39:30-INFO     Created cluster with ID: \"j-2BNKK4O4MQ6Q6\"\n"
     ]
    }
   ],
   "source": [
    "cluster_id_json=os.popen(command).read()\n",
    "#cluster_id=cluster_id_json.split(\": \\\"\",1)[1].split(\"\\\"\\n\")[0]\n",
    "cluster_id=re.split('\\s',cluster_id_json)[1]\n",
    "# Gives EMR cluster information\n",
    "client_EMR = boto3.client('emr', region_name=c['config']['REGION'])\n",
    "logger.warning(f'Created cluster with ID: \"{cluster_id}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "understanding-plant",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 00:39:33-INFO     Creating EMR...\n",
      "25Mar2021 00:39:33-INFO     Cluster status: STARTING\n",
      "25Mar2021 00:40:04-INFO     Cluster status: STARTING\n",
      "25Mar2021 00:40:34-INFO     Cluster status: STARTING\n",
      "25Mar2021 00:41:05-INFO     Cluster status: STARTING\n",
      "25Mar2021 00:41:35-INFO     Cluster status: STARTING\n",
      "25Mar2021 00:42:05-INFO     Cluster status: STARTING\n",
      "25Mar2021 00:42:35-INFO     Cluster status: STARTING\n",
      "25Mar2021 00:43:06-INFO     Cluster status: STARTING\n",
      "25Mar2021 00:43:36-INFO     Cluster status: STARTING\n",
      "25Mar2021 00:44:06-INFO     Cluster status: STARTING\n",
      "25Mar2021 00:44:36-INFO     Cluster status: STARTING\n",
      "25Mar2021 00:45:06-INFO     Cluster status: STARTING\n",
      "25Mar2021 00:45:36-INFO     Cluster status: STARTING\n",
      "25Mar2021 00:46:06-INFO     Cluster status: STARTING\n",
      "25Mar2021 00:46:36-INFO     Cluster status: WAITING\n",
      "25Mar2021 00:47:07-INFO     Cluster successfully created! Starting HAIL installation...\n",
      "25Mar2021 00:47:07-INFO     \n",
      " Total time to provision your cluster: 7.55  minutes\n"
     ]
    }
   ],
   "source": [
    "# Cluster state update\n",
    "status_EMR='STARTING'\n",
    "tic = time.time()\n",
    "# Wait until the cluster is created\n",
    "logger.info('Creating EMR...')\n",
    "\n",
    "while (status_EMR!='EMPTY'):\n",
    "    details_EMR=client_EMR.describe_cluster(ClusterId=cluster_id)\n",
    "    status_EMR=details_EMR.get('Cluster').get('Status').get('State')\n",
    "    logger.info('Cluster status: '+status_EMR)\n",
    "    time.sleep(30)\n",
    "    if (status_EMR=='WAITING'):\n",
    "        logger.warning('Cluster successfully created! Starting HAIL installation...')\n",
    "        toc=time.time()-tic\n",
    "        logger.warning(\"\\n Total time to provision your cluster: %.2f \"%(toc/60)+\" minutes\")\n",
    "        break\n",
    "    if (status_EMR=='TERMINATED_WITH_ERRORS'):\n",
    "        err = \"Cluster un-successfully created. Ending installation...\"\n",
    "        logger.error(err)\n",
    "        sys.exit(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "everyday-committee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 00:47:56-INFO     Master IP address: 18.209.161.105\n"
     ]
    }
   ],
   "source": [
    "# Get public DNS from master node\n",
    "master_dns=details_EMR.get('Cluster').get('MasterPublicDnsName')\n",
    "master_IP=re.sub(\"-\",\".\",master_dns.split(\".\")[0].split(\"ec2-\")[1])\n",
    "logger.info(f'Master IP address: {master_IP}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acquired-uzbekistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 01:03:57-INFO     Creating secure SSH connection to instance...\n",
      "25Mar2021 01:03:57-INFO     Connected (version 2.0, client OpenSSH_7.4)\n",
      "25Mar2021 01:03:58-INFO     Authentication (publickey) successful!\n"
     ]
    }
   ],
   "source": [
    "#Get ssh connection to master instance\n",
    "logger.info('Creating secure SSH connection to instance...')\n",
    "key = paramiko.RSAKey.from_private_key_file(c['config']['PATH_TO_KEY']+c['config']['KEY_NAME']+'.pem')\n",
    "client = paramiko.SSHClient()\n",
    "client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "client.connect(hostname=master_IP, username=\"hadoop\", pkey=key)\n",
    "#Run a quick test on the connection\n",
    "stdin, stdout, stderr = client.exec_command('echo \"Hello\"')\n",
    "assert stdout.readline() == 'Hello\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "organic-possibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 01:03:22-INFO     Copying the keys to the instance with command: \n",
      "scp -o 'StrictHostKeyChecking no' -i /data/hail-ES-GRE.pem /data/hail-ES-GRE.pem hadoop@ec2-18-209-161-105.compute-1.amazonaws.com:/home/hadoop/.ssh/id_rsa\n"
     ]
    }
   ],
   "source": [
    "# Copy the key into the master\n",
    "stdin, stdout, stderr = client.exec_command('mkdir -p ~/.ssh/id_rsa')\n",
    "command='scp -o \\'StrictHostKeyChecking no\\' -i '+\\\n",
    "c['config']['PATH_TO_KEY']+c['config']['KEY_NAME']+'.pem '+\\\n",
    "c['config']['PATH_TO_KEY']+c['config']['KEY_NAME']+'.pem hadoop@'+\\\n",
    "master_dns+':/home/hadoop/.ssh/id_rsa'\n",
    "logger.info(f'Copying the keys to the instance with command: \\n{command}')\n",
    "assert os.system(command) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "charged-tractor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 01:45:45-INFO     Copying the hail installation script to the instance with command: \n",
      "scp -o 'StrictHostKeyChecking no' -i /data/hail-ES-GRE.pem /data/hail-on-AWS-spot-instances/src/install_hail_and_python36.sh hadoop@ec2-18-209-161-105.compute-1.amazonaws.com:/home/hadoop\n"
     ]
    }
   ],
   "source": [
    "# Copy the installation script into the master\n",
    "command='scp -o \\'StrictHostKeyChecking no\\' -i '+\\\n",
    "c['config']['PATH_TO_KEY']+c['config']['KEY_NAME']+'.pem '+\\\n",
    "PATH+'/install_hail_and_python36.sh hadoop@'+master_dns+':/home/hadoop'\n",
    "logger.info(f'Copying the hail installation script to the instance with command: \\n{command}')\n",
    "assert os.system(command) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eastern-language",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 01:32:41-INFO     Copying the python installation script to the instance with command: \n",
      "scp -o 'StrictHostKeyChecking no' -i /data/hail-ES-GRE.pem /data/hail-on-AWS-spot-instances/src/install_python36.sh hadoop@ec2-18-209-161-105.compute-1.amazonaws.com:/home/hadoop\n"
     ]
    }
   ],
   "source": [
    "# Copy the installation script into the master\n",
    "command='scp -o \\'StrictHostKeyChecking no\\' -i '+\\\n",
    "c['config']['PATH_TO_KEY']+c['config']['KEY_NAME']+'.pem '+\\\n",
    "PATH+'/install_python36.sh hadoop@'+master_dns+':/home/hadoop'\n",
    "logger.info(f'Copying the python installation script to the instance with command: \\n{command}')\n",
    "assert os.system(command) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install the software on master\n",
    "VERSION=c['config']['HAIL_VERSION']\n",
    "logger.info(f'Installing hail version {VERSION} et. al on Master')\n",
    "logger.warning(f'This is the public JupyterLab link: \"http://{master_IP}:8192\"')\n",
    "command='./install_hail_and_python36.sh -v '+ VERSION\n",
    "logger.info(f'Executing remote command: \"{command}\"')\n",
    "stdin, stdout, stderr = client.exec_command('cd /home/hadoop/')\n",
    "stdin, stdout, stderr = client.exec_command(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the client connection\n",
    "logger.info('Closing the client connection')\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.warning(f'Successfully started ENR cluster \"{cluster_id}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-meditation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
