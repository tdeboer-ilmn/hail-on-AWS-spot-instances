{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "thick-newark",
   "metadata": {},
   "source": [
    "# Spool up EMR Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proof-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "import sys\n",
    "import botocore\n",
    "import paramiko\n",
    "import re\n",
    "import os\n",
    "import yaml, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "other-vitamin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/hail-on-AWS-spot-instances/src'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = os.path.abspath(os.getcwd())\n",
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "technical-publisher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021021016\n"
     ]
    }
   ],
   "source": [
    "#Setup logging\n",
    "import logging, bluebee\n",
    "from bluebee import bgp\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# create file handler which logs even debug messages\n",
    "logFile = f'{PATH}/spoolup_EMR_cluster.log'\n",
    "fh = logging.FileHandler(logFile)\n",
    "fh.setLevel(logging.INFO)\n",
    "# create console handler with a higher log level\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)-18s-%(levelname)-8s %(message)s', datefmt='%d%b%Y %H:%M:%S')\n",
    "ch.setFormatter(formatter)\n",
    "fh.setFormatter(formatter)\n",
    "# add the handlers to logger\n",
    "logger.addHandler(ch)\n",
    "logger.addHandler(fh)\n",
    "# bgp.api.dump_curl = True\n",
    "# bluebee.logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pressing-spokesman",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 16:49:47-INFO     Configuration settings: {'config': {'EMR_CLUSTER_NAME': 'tdeboer-hail', 'EC2_NAME_TAG': 'tdeboer-hail-EMR', 'OWNER_TAG': 'tdeboer-ilmn', 'PROJECT_TAG': 'GRE_on_ICA', 'REGION': 'us-east-1', 'MASTER_INSTANCE_TYPE': 'm4.large', 'WORKER_INSTANCE_TYPE': 'r4.4xlarge', 'WORKER_COUNT': '4', 'WORKER_BID_PRICE': '0.50', 'MASTER_HD_SIZE': '250', 'WORKER_HD_SIZE': '500', 'SUBNET_ID': '', 'S3_BUCKET': 's3n://ilmn-hail/', 'KEY_NAME': 'hail-ES-GRE', 'PATH_TO_KEY': '/data/', 'WORKER_SECURITY_GROUP': 'sg-0df1e5704ca2a8196', 'MASTER_SECURITY_GROUP': 'sg-0bab1202c0aa453b3', 'HAIL_VERSION': 'current'}}\n"
     ]
    }
   ],
   "source": [
    "#Get the configuration as a yaml object\n",
    "c=yaml.load(open(PATH+\"/config_EMR_spot.yaml\"),Loader=yaml.SafeLoader)\n",
    "logger.info(f'Configuration settings: {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "handed-invention",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 16:49:47-INFO     Executing following command: \n",
      "aws emr create-cluster --applications Name=Hadoop Name=Spark --tags 'project=GRE_on_ICA' 'Owner=tdeboer-ilmn' 'Name=tdeboer-hail-EMR' --ec2-attributes '{\"KeyName\":\"hail-ES-GRE\",\"InstanceProfile\":\"EMR_EC2_DefaultRole\",\"SubnetId\":\"\",\"EmrManagedSlaveSecurityGroup\":\"sg-0df1e5704ca2a8196\",\"EmrManagedMasterSecurityGroup\":\"sg-0bab1202c0aa453b3\"}' --service-role EMR_DefaultRole --release-label emr-5.23.0 --log-uri 's3n://ilmn-hail/' --name 'tdeboer-hail' --instance-groups '[{\"InstanceCount\":1,\"EbsConfiguration\":{\"EbsBlockDeviceConfigs\":[{\"VolumeSpecification\":{\"SizeInGB\":250,\"VolumeType\":\"gp2\"},\"VolumesPerInstance\":1}]},\"InstanceGroupType\":\"MASTER\",\"InstanceType\":\"m4.large\",\"Name\":\"Master-Instance\"},{\"InstanceCount\":4,\"BidPrice\":\"0.50\",\"EbsConfiguration\":{\"EbsBlockDeviceConfigs\":[{\"VolumeSpecification\":{\"SizeInGB\":500,\"VolumeType\":\"gp2\"},\"VolumesPerInstance\":1}]},\"InstanceGroupType\":\"CORE\",\"InstanceType\":\"r4.4xlarge\",\"Name\":\"Core-Group\"}]' --configurations '[{\"Classification\":\"spark\",\"Properties\":{\"maximizeResourceAllocation\":\"true\"}},{\"Classification\":\"yarn-site\",\"Properties\":{\"yarn.nodemanager.vmem-check-enabled\":\"false\"},\"Configurations\":[]}]' --auto-scaling-role EMR_AutoScaling_DefaultRole --ebs-root-volume-size 32 --scale-down-behavior TERMINATE_AT_TASK_COMPLETION --region us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Spot instances and different CORE/MASTER instances\n",
    "command='aws emr create-cluster --applications Name=Hadoop Name=Spark --tags \\'project='+\\\n",
    "c['config']['PROJECT_TAG']+'\\' \\'Owner='+c['config']['OWNER_TAG']+\\\n",
    "'\\' \\'Name='+c['config']['EC2_NAME_TAG']+'\\' --ec2-attributes \\'{\"KeyName\":\"'+\\\n",
    "c['config']['KEY_NAME']+'\",\"InstanceProfile\":\"EMR_EC2_DefaultRole\",\"SubnetId\":\"'+\\\n",
    "c['config']['SUBNET_ID']+'\",\"EmrManagedSlaveSecurityGroup\":\"'+c['config']['WORKER_SECURITY_GROUP']+\\\n",
    "'\",\"EmrManagedMasterSecurityGroup\":\"'+c['config']['MASTER_SECURITY_GROUP']+\\\n",
    "'\"}\\' --service-role EMR_DefaultRole --release-label emr-5.23.0 --log-uri \\''+\\\n",
    "c['config']['S3_BUCKET']+'\\' --name \\''+c['config']['EMR_CLUSTER_NAME']+\\\n",
    "'\\' --instance-groups \\'[{\"InstanceCount\":1,\"EbsConfiguration\":{\"EbsBlockDeviceConfigs\":[{\"VolumeSpecification\":{\"SizeInGB\":'+\\\n",
    "c['config']['MASTER_HD_SIZE']+',\"VolumeType\":\"gp2\"},\"VolumesPerInstance\":1}]},\"InstanceGroupType\":\"MASTER\",\"InstanceType\":\"'+\\\n",
    "c['config']['MASTER_INSTANCE_TYPE']+'\",\"Name\":\"Master-Instance\"},{\"InstanceCount\":'+\\\n",
    "c['config']['WORKER_COUNT']+',\"BidPrice\":\"'+c['config']['WORKER_BID_PRICE']+\\\n",
    "'\",\"EbsConfiguration\":{\"EbsBlockDeviceConfigs\":[{\"VolumeSpecification\":{\"SizeInGB\":'+\\\n",
    "c['config']['WORKER_HD_SIZE']+',\"VolumeType\":\"gp2\"},\"VolumesPerInstance\":1}]},\"InstanceGroupType\":\"CORE\",\"InstanceType\":\"'+\\\n",
    "c['config']['WORKER_INSTANCE_TYPE']+\\\n",
    "'\",\"Name\":\"Core-Group\"}]\\' --configurations \\'[{\"Classification\":\"spark\",\"Properties\":{\"maximizeResourceAllocation\":\"true\"}},{\"Classification\":\"yarn-site\",\"Properties\":{\"yarn.nodemanager.vmem-check-enabled\":\"false\"},\"Configurations\":[]}]\\' --auto-scaling-role EMR_AutoScaling_DefaultRole --ebs-root-volume-size 32 --scale-down-behavior TERMINATE_AT_TASK_COMPLETION --region '+\\\n",
    "c['config']['REGION']\n",
    "logger.info(f'Executing following command: \\n{command}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spanish-wilderness",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 16:49:48-INFO     Found credentials in shared credentials file: ~/.aws/credentials\n",
      "25Mar2021 16:49:48-WARNING  Created cluster with ID: \"j-EAP4X335DCXH\"\n"
     ]
    }
   ],
   "source": [
    "cluster_id_json=os.popen(command).read()\n",
    "#My default profile exports TEXT\n",
    "cluster_id=re.split('\\s',cluster_id_json)[1]\n",
    "# Gives EMR cluster information\n",
    "client_EMR = boto3.client('emr', region_name=c['config']['REGION'])\n",
    "logger.warning(f'Created cluster with ID: \"{cluster_id}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "miniature-saying",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 16:49:48-INFO     Creating EMR...\n",
      "25Mar2021 16:49:48-INFO     Cluster status: STARTING\n",
      "25Mar2021 16:50:18-INFO     Cluster status: STARTING\n",
      "25Mar2021 16:50:49-INFO     Cluster status: STARTING\n",
      "25Mar2021 16:51:19-INFO     Cluster status: STARTING\n",
      "25Mar2021 16:51:49-INFO     Cluster status: STARTING\n",
      "25Mar2021 16:52:19-INFO     Cluster status: STARTING\n",
      "25Mar2021 16:52:49-INFO     Cluster status: STARTING\n",
      "25Mar2021 16:53:19-INFO     Cluster status: STARTING\n",
      "25Mar2021 16:53:49-INFO     Cluster status: STARTING\n",
      "25Mar2021 16:54:20-INFO     Cluster status: STARTING\n",
      "25Mar2021 16:54:50-INFO     Cluster status: STARTING\n",
      "25Mar2021 16:55:20-INFO     Cluster status: STARTING\n",
      "25Mar2021 16:55:50-INFO     Cluster status: STARTING\n",
      "25Mar2021 16:56:20-INFO     Cluster status: STARTING\n",
      "25Mar2021 16:56:50-INFO     Cluster status: WAITING\n",
      "25Mar2021 16:57:20-WARNING  Cluster successfully created! Starting HAIL installation...\n",
      "25Mar2021 16:57:20-WARNING  \n",
      " Total time to provision your cluster: 7.53  minutes\n"
     ]
    }
   ],
   "source": [
    "# Cluster state update\n",
    "status_EMR='STARTING'\n",
    "tic = time.time()\n",
    "# Wait until the cluster is created\n",
    "logger.info('Creating EMR...')\n",
    "\n",
    "while (status_EMR!='EMPTY'):\n",
    "    details_EMR=client_EMR.describe_cluster(ClusterId=cluster_id)\n",
    "    status_EMR=details_EMR.get('Cluster').get('Status').get('State')\n",
    "    logger.info('Cluster status: '+status_EMR)\n",
    "    time.sleep(30)\n",
    "    if (status_EMR=='WAITING'):\n",
    "        logger.warning('Cluster successfully created! Starting HAIL installation...')\n",
    "        toc=time.time()-tic\n",
    "        logger.warning(\"\\n Total time to provision your cluster: %.2f \"%(toc/60)+\" minutes\")\n",
    "        break\n",
    "    if (status_EMR=='TERMINATED_WITH_ERRORS'):\n",
    "        err = \"Cluster un-successfully created. Ending installation...\"\n",
    "        logger.error(err)\n",
    "        sys.exit(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "incident-memory",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 16:57:20-INFO     Master IP address: 54.159.211.191\n"
     ]
    }
   ],
   "source": [
    "# Get public DNS from master node\n",
    "master_dns=details_EMR.get('Cluster').get('MasterPublicDnsName')\n",
    "master_IP=re.sub(\"-\",\".\",master_dns.split(\".\")[0].split(\"ec2-\")[1])\n",
    "logger.info(f'Master IP address: {master_IP}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "foster-satellite",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 16:57:20-INFO     Creating secure SSH connection to instance...\n",
      "25Mar2021 16:57:20-INFO     Connected (version 2.0, client OpenSSH_7.4)\n",
      "25Mar2021 16:57:20-INFO     Authentication (publickey) successful!\n"
     ]
    }
   ],
   "source": [
    "#Get ssh connection to master instance\n",
    "logger.info('Creating secure SSH connection to instance...')\n",
    "key = paramiko.RSAKey.from_private_key_file(c['config']['PATH_TO_KEY']+c['config']['KEY_NAME']+'.pem')\n",
    "client = paramiko.SSHClient()\n",
    "client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "client.connect(hostname=master_IP, username=\"hadoop\", pkey=key)\n",
    "#Run a quick test on the connection\n",
    "stdin, stdout, stderr = client.exec_command('echo \"Hello\"')\n",
    "assert stdout.readline() == 'Hello\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "oriental-gardening",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 16:57:21-INFO     Copying the keys to the instance with command: \n",
      "scp -o 'StrictHostKeyChecking no' -i /data/hail-ES-GRE.pem /data/hail-ES-GRE.pem hadoop@ec2-54-159-211-191.compute-1.amazonaws.com:/home/hadoop/.ssh/id_rsa\n"
     ]
    }
   ],
   "source": [
    "# Copy the key into the master\n",
    "stdin, stdout, stderr = client.exec_command('mkdir -p ~/.ssh/id_rsa')\n",
    "command='scp -o \\'StrictHostKeyChecking no\\' -i '+\\\n",
    "c['config']['PATH_TO_KEY']+c['config']['KEY_NAME']+'.pem '+\\\n",
    "c['config']['PATH_TO_KEY']+c['config']['KEY_NAME']+'.pem hadoop@'+\\\n",
    "master_dns+':/home/hadoop/.ssh/id_rsa'\n",
    "logger.info(f'Copying the keys to the instance with command: \\n{command}')\n",
    "assert os.system(command) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "oriental-natural",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 16:57:21-INFO     Copying the hail installation script to the instance with command: \n",
      "scp -o 'StrictHostKeyChecking no' -i /data/hail-ES-GRE.pem /data/hail-on-AWS-spot-instances/src/install_hail_and_python36.sh hadoop@ec2-54-159-211-191.compute-1.amazonaws.com:/home/hadoop\n"
     ]
    }
   ],
   "source": [
    "# Copy the hail installation script into the master\n",
    "command='scp -o \\'StrictHostKeyChecking no\\' -i '+\\\n",
    "c['config']['PATH_TO_KEY']+c['config']['KEY_NAME']+'.pem '+\\\n",
    "PATH+'/install_hail_and_python36.sh hadoop@'+master_dns+':/home/hadoop'\n",
    "logger.info(f'Copying the hail installation script to the instance with command: \\n{command}')\n",
    "assert os.system(command) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "powered-equivalent",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 16:57:21-INFO     Copying the python installation script to the instance with command: \n",
      "scp -o 'StrictHostKeyChecking no' -i /data/hail-ES-GRE.pem /data/hail-on-AWS-spot-instances/src/install_python36.sh hadoop@ec2-54-159-211-191.compute-1.amazonaws.com:/home/hadoop\n"
     ]
    }
   ],
   "source": [
    "# Copy the installation script into the master\n",
    "command='scp -o \\'StrictHostKeyChecking no\\' -i '+\\\n",
    "c['config']['PATH_TO_KEY']+c['config']['KEY_NAME']+'.pem '+\\\n",
    "PATH+'/install_python36.sh hadoop@'+master_dns+':/home/hadoop'\n",
    "logger.info(f'Copying the python installation script to the instance with command: \\n{command}')\n",
    "assert os.system(command) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "decimal-account",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 16:57:21-INFO     Installing hail version current et. al on Master\n",
      "25Mar2021 16:57:21-WARNING  This is the public JupyterLab link: \"http://54.159.211.191:8192\"\n",
      "25Mar2021 16:57:21-INFO     Executing remote command: \"./install_hail_and_python36.sh -v current\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-db9572a528ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mstdin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd /home/hadoop/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstdin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/paramiko/file.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/paramiko/file.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/paramiko/channel.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/paramiko/channel.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, nbytes)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \"\"\"\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPipeTimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/paramiko/buffered_pipe.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nbytes, timeout)\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0mthen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                         \u001b[0mtimeout\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Install the software on master\n",
    "VERSION=c['config']['HAIL_VERSION']\n",
    "logger.info(f'Installing hail version {VERSION} et. al on Master')\n",
    "logger.warning(f'This is the public JupyterLab link: \"http://{master_IP}:8192\"')\n",
    "command='./install_hail_and_python36.sh -v '+ VERSION\n",
    "logger.info(f'Executing remote command: \"{command}\"')\n",
    "stdin, stdout, stderr = client.exec_command('cd /home/hadoop/')\n",
    "stdin, stdout, stderr = client.exec_command(command)\n",
    "for line in stdout:\n",
    "    logger.info(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "focal-eagle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 18:38:24-INFO     Closing the client connection\n"
     ]
    }
   ],
   "source": [
    "# close the client connection\n",
    "logger.info('Closing the client connection')\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "considered-lighting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25Mar2021 18:38:25-WARNING  Successfully started ENR cluster \"j-EAP4X335DCXH\"\n"
     ]
    }
   ],
   "source": [
    "logger.warning(f'Successfully started ENR cluster \"{cluster_id}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-fever",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
